---
title: "Using external evaluation with CDM"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
vignette: >
  %\VignetteIndexEntry{Using external evaluation with CDM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Setup in internal and external nodes

## Definitions

```{r setup}
library(LearningWithExternalStats)
library(Eunomia)  # v1.0.2
library(FeatureExtraction)  # v3.2.0
library(PatientLevelPrediction)  # v6.0.4
library(glue)

# Activate Eunomia demo database
connectionDetails <- Eunomia::getEunomiaConnectionDetails()
Eunomia::createCohorts(connectionDetails)
```

Data definitions

```{r}
outcomeId <- 3
internalTargetId <- 1
externalTargetId <- 2

covSettings <- createCovariateSettings(
  useDemographicsGender = TRUE,
  useDemographicsAge = TRUE,
  useConditionGroupEraLongTerm = TRUE,
  useConditionGroupEraAnyTimePrior = TRUE,
  useDrugGroupEraLongTerm = TRUE,
  useDrugGroupEraAnyTimePrior = TRUE,
  useVisitConceptCountLongTerm = TRUE,
  longTermStartDays = -365,
  endDays = -1)

databaseDetails <- createDatabaseDetails(
  connectionDetails = connectionDetails,
  cdmDatabaseSchema = "main",
  cdmDatabaseName = '',
  cdmDatabaseId = '',  # ?
  tempEmulationSchema = NULL,  # is this important to avoid further errors in getPlpData?
  cohortDatabaseSchema = "main",
  cohortTable = "cohort",
  targetId = internalTargetId,
  outcomeDatabaseSchema = "main",
  outcomeTable = "cohort",
  outcomeIds = outcomeId,
  cdmVersion = 5  #?
)

restrictPlpDataSettings <- createRestrictPlpDataSettings()  # sampleSize = 1000
```

## Utilities

```{r}
transformPlpDataToDataFrame <- function(plpData, populationSettings, outcomeId) {
  #### new
  if(!is.null(plpData)){
    labels <- PatientLevelPrediction::createStudyPopulation(
      plpData = plpData,
      outcomeId = outcomeId,
      populationSettings = populationSettings
    )
  }
  # convert to matrix
  dataObject <- PatientLevelPrediction::toSparseM(
    plpData = plpData,
    cohort = labels
  )
  #sparse matrix: dataObject$dataMatrix
  #labels: dataObject$labels
  columnDetails <- as.data.frame(dataObject$covariateRef)

  cnames <- columnDetails$covariateName[order(columnDetails$columnId)]

  ipMat <- as.matrix(dataObject$dataMatrix)
  ipdata <- as.data.frame(ipMat)
  colnames(ipdata) <-  makeFriendlyNames(cnames)
  ipdata$outcome <- dataObject$labels$outcomeCount
  rownames(ipdata) <- dataObject$labels$rowId
  return(ipdata)

}

makeFriendlyNames <- function(columnNames){

  columnNames <- gsub("[[:punct:]]", " ", columnNames)
  columnNames <- gsub(" ", "_", columnNames)
  return(columnNames)

}


summarizeResults <- function(s, evaluation) {

  cat(evaluation, 'AUROC:\t', s[(s['metric']=='AUROC') & (s['evaluation']==evaluation), 'value'][[1]], '\n')
  f <- c(
    'populationSize',
    'outcomeCount',
    'AUROC',
    '95% lower AUROC',
    '95% upper AUROC',
    # AUPRC
    'brier score',
    # brier score scaled
    # Eavg
    # E90
    # Emax
    'calibrationInLarge mean prediction',
    'calibrationInLarge observed risk'
  )
  print(format(s[(s['evaluation']==evaluation) & (s[['metric']] %in% f),c('metric', 'value')], digits=2))

}
```

# Internal node

Generate internal data

```{r}
internalPlpData <- getPlpData(
    databaseDetails = databaseDetails,
    covariateSettings = covSettings,
    restrictPlpDataSettings = restrictPlpDataSettings)
```

Prediction model definitions

```{r}

populationSettings <- createStudyPopulationSettings(
  washoutPeriod = 364,
  firstExposureOnly = FALSE,
  removeSubjectsWithPriorOutcome = TRUE,
  priorOutcomeLookback = 9999,
  riskWindowStart = 1,
  riskWindowEnd = 365,
  minTimeAtRisk = 364,
  requireTimeAtRisk = TRUE,
  includeAllOutcomes = TRUE)

splitSettings <- createDefaultSplitSetting(
  trainFraction = 0.75,
  testFraction = 0.25,
  type = 'stratified',
  nfold = 2,
  splitSeed = 1234
)

sampleSettings <- createSampleSettings()
featureEngineeringSettings <- createFeatureEngineeringSettings()
preprocessSettings <- createPreprocessSettings(
  minFraction = 0.01,
  normalize = T,
  removeRedundancy = T
)


lrModel <- setLassoLogisticRegression()

executeSettings = createExecuteSettings(
  runSplitData = T,
  runSampleData = T,
  runfeatureEngineering = T,
  runPreprocessData = T,
  runModelDevelopment = T,
  runCovariateSummary = T
)

```

Train the model

```{r}

internalResults <- runPlp(
    plpData = internalPlpData,
    outcomeId = outcomeId,
    analysisId = '../singleDemo',
    analysisName = 'Demonstration of runPlp for training single PLP models',
    populationSettings = populationSettings,
    splitSettings = splitSettings,
    sampleSettings = sampleSettings,
    featureEngineeringSettings = featureEngineeringSettings,
    preprocessSettings = preprocessSettings,
    modelSettings = lrModel,
    logSettings = createLogSettings(),
    executeSettings = executeSettings,
    saveDirectory = file.path(getwd(), '..', 'singlePlp')
  )

# summarizeResults(internalResults$performanceEvaluation$evaluationStatistics, 'Test')
```

Identify model covariates. These will be used in the estimation algorithm.

```{r}
covariateImportance <- internalResults$model$covariateImportance
importantCovariates <- covariateImportance[abs(covariateImportance['covariateValue']) > 0, ]
estimationCovariates <- importantCovariates[['covariateName']]
estimationCovariates <- makeFriendlyNames(estimationCovariates)
```

# External node

## Generate PLP data and evaluate model

```{r}
externalDatabaseDetails <- createDatabaseDetails(
  connectionDetails = connectionDetails,
  cdmDatabaseSchema = "main",
  cdmDatabaseName = '',
  cdmDatabaseId = '',  # ?
  tempEmulationSchema = NULL,  # is this important to avoid further errors in getPlpData?
  cohortDatabaseSchema = "main",
  cohortTable = "cohort",
  targetId = externalTargetId,
  outcomeDatabaseSchema = "main",
  outcomeTable = "cohort",
  outcomeIds = outcomeId,
  cdmVersion = 5  #?
)

externalPlpData <- getPlpData(
  databaseDetails = externalDatabaseDetails,
  covariateSettings = covSettings,
  restrictPlpDataSettings = restrictPlpDataSettings)

externalResults <- externalValidateDbPlp(  # TODO how should we avoid duplicated generation of plpData?
  internalResults$model,
  validationDatabaseDetails = externalDatabaseDetails)
```

## Prepare statistics for sharing

```{r}
externalXY <- transformPlpDataToDataFrame(externalPlpData, populationSettings, outcomeId = outcomeId)
# TODO verify that estimation covariates are included
ZExt <- computeTable1LikeTransformation(
  externalXY[c(estimationCovariates, 'outcome')], outcomeBalance = T, outcomeCol = 'outcome')
muExt <- colMeans(ZExt)
```

# Internal node: evaluation of external dataset peformence using internal dataset

```{r}
# Identify and align predictions with internal data
tstIdx <- internalResults$prediction$evaluationType == 'Test'
cvIdx <- internalResults$prediction$evaluationType == 'CV'
trainIdx <- internalResults$prediction$evaluationType == 'Train'
evalIdx <- tstIdx | trainIdx
prediction <- internalResults$prediction[evalIdx, ]
prediction <- prediction[order(prediction$rowId), ]

# Prepare input for evaluation
internalXY <- transformPlpDataToDataFrame(internalPlpData, populationSettings, outcomeId = 3)
if (sum(prediction$outcomeCount != internalXY[['outcome']]) > 0)  # TODO make if more rigorous using rowId
  stop('need to allign prediction and internalXY')
ZInt <- computeTable1LikeTransformation(
  internalXY[c(estimationCovariates, 'outcome')], outcomeBalance = T, outcomeCol = 'outcome')

# TODO - check if we need to hand the outcome
# TODO add a test to the package to make sure no: Error in rep(TRUE, n1) : invalid 'times' argument. check internalData
# TODO check vector lengths

internalData <- list(z=ZInt, p = prediction$value, y = internalXY[['outcome']])
estimatedResults <- estimateExternalPerformanceFromStats(  # TODO automatic selection of parameters?
  internalData, muExt, divergence = 'entropy', lambda = 1e-2, minW = 1e-6, optimizationMethod = 'dual', nboot = 10)
```

# Compare evaluation and real results

```{r}
summarizeResults(internalResults$performanceEvaluation$evaluationStatistics, 'Test')
summarizeResults(externalResults[[2]]$performanceEvaluation$evaluationStatistics, 'Validation')

cat('Estimated metrics:\n')
print(estimationSummaryToDF(estimatedResults$summary))
```
