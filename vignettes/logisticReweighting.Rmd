---
title: "Evaluation using external statistics - example with a logisitic model"
output: 
  pdf_document:
    number_sections: no
    toc: no
  rmarkdown::html_vignette:
    number_sections: no
    toc: no
vignette: >
  %\VignetteIndexEntry{Evaluation using external statistics - example with a logisitic model}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This example demonstrates re-weighting of a pre-trained logistic
regression model to evalute external performence using an internal test
set and statistics from the external set.

## Setup

First we import the libraries

```{r setup}
library(LearningWithExternalStats)
library(glue)
library(pROC)
library(glmnet)
```

Next we load data and model objects:

```{r}
d <- LearningWithExternalStats::anchorData1
model1 <- LearningWithExternalStats::anchorLR1
```

## Prediction in internal dataset

Predict the label probabilities in the internal test set

```{r}
xFeatures <- colnames(d$externalTest)[1:(ncol(d$externalTest)-1)]
internalX <- sapply(d$internalTest[xFeatures], as.numeric)
pInternal <- predict(model1, internalX, type = "response", s = "lambda.1se")[,1]
internalAUC <- auc(roc(d$internalTest[['Y']], pInternal, direction = "<", quiet = T))
cat(glue('\nInternal AUC = {format(internalAUC, digits=3)}'), '\n')
```

## Estimation using reweighting

First we should compute features that are used for reweighting.
Specifically, we compute interactions between features and outcomes and
squared features. These features allow to to compare and re-weight means
and variances of every feature in every label group. The features of the
external set are averaged. The re-weighting algorithm will use the means
of the external features and the entire internal features matrix.

```{r}
dTransformedInt <- computeTable1LikeTransformation(d$internalTest, outcomeBalance=TRUE)
dTransformedExt <- computeTable1LikeTransformation(d$externalTest, outcomeBalance=TRUE)
muExt <- colMeans(dTransformedExt)
```

Before we re-weight, we should define parameters of the algorithms. The
`divergence` parameter defines the type of divergence between the
weighted distribution and the uniform distribution. `lambda` controls
the tradeoff between matching accuracy and closeness to the uniform
distribution. 'minW' is the minimum allowed weight. `optimizationMethod`
can be `'dual'` or `'primal'`:

```{r}
reweightSettings <- createReweightSettings(
  divergence = 'entropy', 
  lambda = 1e-2, 
  minW = 1e-6, 
  optimizationMethod = 'dual'
)
```

Now we are ready to estimate:

```{r}
internalData <- list(z=dTransformedInt, p = pInternal, y = d$internalTest[['Y']])

estimatedResults <- estimateExternalPerformanceFromStatistics(
  internalData = internalData,
  externalStats = muExt,
  reweightSettings = reweightSettings,
  nboot = 0
)
```
and display results:
```{r}
print(format(estimatedResults$summary, digits=3))
```

The entropy is a measure of the distance between the original and
reweighted distributions.

## Comparison to external set

Compare to real performance in the test set

```{r}
xExternal <- sapply(d$externalTest[xFeatures], as.numeric)
pExternal <- predict(model1, xExternal, type = "response", s = "lambda.1se")[,1]
extAuc <- auc(roc(d$externalTest[['Y']], pExternal, quiet = TRUE, direction='<'))
cat(glue('\nExternal AUC = {format(extAuc, digits=3)}'), '\n')
```
